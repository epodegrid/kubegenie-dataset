apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: elasticsearch-client-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: elasticsearch-client
---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: elasticsearch-data-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: elasticsearch-data
---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: release-name-logstash-pdb
  labels:
    app: release-name-logstash
    chart: logstash
    heritage: Helm
    release: release-name
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: release-name-logstash
---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: elasticsearch-master-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: elasticsearch-master
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-filebeat
  labels:
    app: release-name-filebeat
    chart: filebeat-7.7.1
    heritage: Helm
    release: release-name
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-filebeat-config
  labels:
    app: release-name-filebeat
    chart: filebeat-7.7.1
    heritage: Helm
    release: release-name
data:
  filebeat.yml: |
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
      - add_kubernetes_metadata:
          host: ${NODE_NAME}
          matchers:
          - logs_path:
              logs_path: "/var/log/containers/"

    output.elasticsearch:
      host: '${NODE_NAME}'
      hosts: '${ELASTICSEARCH_HOSTS:elasticsearch-master:9200}'
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: release-name-filebeat-cluster-role
  labels:
    app: release-name-filebeat
    chart: filebeat-7.7.1
    heritage: Helm
    release: release-name
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
      - pods
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: release-name-filebeat-cluster-role-binding
  labels:
    app: release-name-filebeat
    chart: filebeat-7.7.1
    heritage: Helm
    release: release-name
roleRef:
  kind: ClusterRole
  name: release-name-filebeat-cluster-role
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: release-name-filebeat
    namespace: default
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-client
  labels:
    heritage: Helm
    release: release-name
    chart: client
    app: elasticsearch-client
  annotations: {}
spec:
  type: ClusterIP
  selector:
    heritage: Helm
    release: release-name
    chart: client
    app: elasticsearch-client
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-client-headless
  labels:
    heritage: Helm
    release: release-name
    chart: client
    app: elasticsearch-client
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: elasticsearch-client
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-data
  labels:
    heritage: Helm
    release: release-name
    chart: data
    app: elasticsearch-data
  annotations: {}
spec:
  type: ClusterIP
  selector:
    heritage: Helm
    release: release-name
    chart: data
    app: elasticsearch-data
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-data-headless
  labels:
    heritage: Helm
    release: release-name
    chart: data
    app: elasticsearch-data
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: elasticsearch-data
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-kibana
  labels:
    app: kibana
    release: release-name
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5601
      protocol: TCP
      name: http
      targetPort: 5601
  selector:
    app: kibana
    release: release-name
---
kind: Service
apiVersion: v1
metadata:
  name: release-name-logstash
  labels:
    app: release-name-logstash
    chart: logstash
    heritage: Helm
    release: release-name
  annotations: {}
spec:
  type: ClusterIP
  selector:
    app: release-name-logstash
    chart: logstash
    heritage: Helm
    release: release-name
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: beats
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: master
    app: elasticsearch-master
  annotations: {}
spec:
  type: ClusterIP
  selector:
    heritage: Helm
    release: release-name
    chart: master
    app: elasticsearch-master
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master-headless
  labels:
    heritage: Helm
    release: release-name
    chart: master
    app: elasticsearch-master
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: elasticsearch-master
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: release-name-filebeat
  labels:
    app: release-name-filebeat
    chart: filebeat-7.7.1
    heritage: Helm
    release: release-name
spec:
  selector:
    matchLabels:
      app: release-name-filebeat
      release: release-name
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        configChecksum: 7cad89731669e6dbe79ed1435d6443b2cb535ce5e1c8d968d04a08f07f99661
      name: release-name-filebeat
      labels:
        app: release-name-filebeat
        chart: filebeat-7.7.1
        heritage: Helm
        release: release-name
    spec:
      serviceAccountName: release-name-filebeat
      terminationGracePeriodSeconds: 30
      volumes:
        - name: filebeat-config
          configMap:
            defaultMode: 384
            name: release-name-filebeat-config
        - name: data
          hostPath:
            path: /var/lib/release-name-filebeat-default-data
            type: DirectoryOrCreate
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: varlog
          hostPath:
            path: /var/log
        - name: varrundockersock
          hostPath:
            path: /var/run/docker.sock
      containers:
        - name: filebeat
          image: docker.elastic.co/beats/filebeat:7.7.1
          imagePullPolicy: IfNotPresent
          args:
            - -e
            - -E
            - http.enabled=true
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  curl --fail 127.0.0.1:5066
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  filebeat test output
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          resources:
            limits:
              cpu: 1000m
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 100Mi
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: ELASTICSEARCH_HOST
              value: elasticsearch-client
            - name: ELASTICSEARCH_PORT
              value: "9200"
          securityContext:
            privileged: false
            runAsUser: 10935
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
            seccompProfile:
              type: RuntimeDefault
          volumeMounts:
            - name: filebeat-config
              mountPath: /usr/share/filebeat/filebeat.yml
              readOnly: true
              subPath: filebeat.yml
            - name: data
              mountPath: /usr/share/filebeat/data
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
            - name: varlog
              mountPath: /var/log
              readOnly: true
            - name: varrundockersock
              mountPath: /var/run/docker.sock
              readOnly: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-kibana
  labels:
    app: kibana
    release: release-name
    heritage: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: kibana
      release: release-name
  template:
    metadata:
      labels:
        app: kibana
        release: release-name
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
      volumes: null
      containers:
        - name: kibana
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 11987
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/kibana/kibana:7.7.1
          imagePullPolicy: IfNotPresent
          env:
            - name: ELASTICSEARCH_HOSTS
              value: http://elasticsearch-client:9200
            - name: SERVER_HOST
              value: 0.0.0.0
            - name: NODE_OPTIONS
              value: --max-old-space-size=1800
            - name: LOGGING_QUIET
              value: "false"
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  http () {
                      local path="${1}"
                      set -- -XGET -s --fail -L

                      if [ -n "${ELASTICSEARCH_USERNAME}" ] && [ -n "${ELASTICSEARCH_PASSWORD}" ]; then
                        set -- "$@" -u "${ELASTICSEARCH_USERNAME}:${ELASTICSEARCH_PASSWORD}"
                      fi

                      STATUS=$(curl --output /dev/null --write-out "%{http_code}" -k "$@" "http://localhost:5601${path}")
                      if [[ "${STATUS}" -eq 200 ]]; then
                        exit 0
                      fi

                      echo "Error: Got HTTP code ${STATUS} but expected a 200"
                      exit 1
                  }

                  http "/app/kibana"
          ports:
            - containerPort: 5601
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 512Mi
          volumeMounts: null
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-client
  labels:
    heritage: Helm
    release: release-name
    chart: client
    app: elasticsearch-client
  annotations:
    esMajorVersion: "7"
spec:
  serviceName: elasticsearch-client-headless
  selector:
    matchLabels:
      app: elasticsearch-client
  replicas: 2
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: elasticsearch-client
      labels:
        heritage: Helm
        release: release-name
        chart: client
        app: elasticsearch-client
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - elasticsearch-client
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      volumes: null
      initContainers:
        - name: configure-sysctl
          securityContext:
            runAsUser: 11853
            privileged: true
            capabilities:
              drop:
                "": NET_RAW
          image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
          imagePullPolicy: IfNotPresent
          command:
            - sysctl
            - -w
            - vm.max_map_count=262144
          resources:
            seccompProfile:
              type: RuntimeDefault
      containers:
        - name: client
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 11034
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=green&timeout=1s" )
                  # Once it has started only check that the node itself is responding
                  START_FILE=/tmp/.es_start_file

                  http () {
                    local path="${1}"
                    local args="${2}"
                    set -- -XGET -s

                    if [ "$args" != "" ]; then
                      set -- "$@" $args
                    fi

                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    fi

                    curl --output /dev/null -k "$@" "http://127.0.0.1:9200${path}"
                  }

                  if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy'
                    HTTP_CODE=$(http "/" "-w %{http_code}")
                    RC=$?
                    if [[ ${RC} -ne 0 ]]; then
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with RC ${RC}"
                      exit ${RC}
                    fi
                    # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                    if [[ ${HTTP_CODE} == "200" ]]; then
                      exit 0
                    elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                      exit 0
                    else
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                      exit 1
                    fi

                  else
                    echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=green&timeout=1s" "--fail" ; then
                      touch ${START_FILE}
                      exit 0
                    else
                      echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                      exit 1
                    fi
                  fi
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          resources:
            limits:
              cpu: "1.5"
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: discovery.seed_hosts
              value: elasticsearch-master-headless
            - name: cluster.name
              value: elasticsearch
            - name: network.host
              value: 0.0.0.0
            - name: ES_JAVA_OPTS
              value: -Xmx1g -Xms1g
            - name: node.data
              value: "false"
            - name: node.ingest
              value: "true"
            - name: node.master
              value: "false"
            - name: XPACK_MONITORING_ENABLED
              value: "true"
          volumeMounts: null
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-data
  labels:
    heritage: Helm
    release: release-name
    chart: data
    app: elasticsearch-data
  annotations:
    esMajorVersion: "7"
spec:
  serviceName: elasticsearch-data-headless
  selector:
    matchLabels:
      app: elasticsearch-data
  replicas: 2
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 20Gi
  template:
    metadata:
      name: elasticsearch-data
      labels:
        heritage: Helm
        release: release-name
        chart: data
        app: elasticsearch-data
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - elasticsearch-data
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      volumes: null
      initContainers: null
      containers:
        - name: data
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 10774
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=green&timeout=1s" )
                  # Once it has started only check that the node itself is responding
                  START_FILE=/tmp/.es_start_file

                  http () {
                    local path="${1}"
                    local args="${2}"
                    set -- -XGET -s

                    if [ "$args" != "" ]; then
                      set -- "$@" $args
                    fi

                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    fi

                    curl --output /dev/null -k "$@" "http://127.0.0.1:9200${path}"
                  }

                  if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy'
                    HTTP_CODE=$(http "/" "-w %{http_code}")
                    RC=$?
                    if [[ ${RC} -ne 0 ]]; then
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with RC ${RC}"
                      exit ${RC}
                    fi
                    # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                    if [[ ${HTTP_CODE} == "200" ]]; then
                      exit 0
                    elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                      exit 0
                    else
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                      exit 1
                    fi

                  else
                    echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=green&timeout=1s" "--fail" ; then
                      touch ${START_FILE}
                      exit 0
                    else
                      echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                      exit 1
                    fi
                  fi
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          resources:
            limits:
              cpu: "1.5"
              memory: 3Gi
            requests:
              cpu: 1000m
              memory: 2Gi
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: discovery.seed_hosts
              value: elasticsearch-master-headless
            - name: cluster.name
              value: elasticsearch
            - name: network.host
              value: 0.0.0.0
            - name: ES_JAVA_OPTS
              value: -Xmx1536m -Xms1536m
            - name: node.data
              value: "true"
            - name: node.ingest
              value: "false"
            - name: node.master
              value: "false"
            - name: XPACK_MONITORING_ENABLED
              value: "true"
          volumeMounts:
            - name: elasticsearch-data
              mountPath: /usr/share/elasticsearch/data
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-logstash
  labels:
    app: release-name-logstash
    chart: logstash
    heritage: Helm
    release: release-name
spec:
  serviceName: release-name-logstash
  selector:
    matchLabels:
      app: release-name-logstash
      release: release-name
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: release-name-logstash
      labels:
        app: release-name-logstash
        chart: logstash
        heritage: Helm
        release: release-name
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - release-name-logstash
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      volumes: null
      containers:
        - name: logstash
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 10955
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/logstash/logstash:7.7.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 90
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9600
            - containerPort: 5044
              name: beats
          resources:
            limits:
              cpu: 1000m
              memory: 1536Mi
            requests:
              cpu: 100m
              memory: 1536Mi
          env:
            - name: LS_JAVA_OPTS
              value: -Xmx1g -Xms1g
            - name: ELASTICSEARCH_HOST
              value: elasticsearch-client
            - name: ELASTICSEARCH_PORT
              value: "9200"
          volumeMounts: null
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: master
    app: elasticsearch-master
  annotations:
    esMajorVersion: "7"
spec:
  serviceName: elasticsearch-master-headless
  selector:
    matchLabels:
      app: elasticsearch-master
  replicas: 2
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - metadata:
        name: elasticsearch-master
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 4Gi
  template:
    metadata:
      name: elasticsearch-master
      labels:
        heritage: Helm
        release: release-name
        chart: master
        app: elasticsearch-master
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - elasticsearch-master
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      volumes: null
      initContainers: null
      containers:
        - name: master
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 10833
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=green&timeout=1s" )
                  # Once it has started only check that the node itself is responding
                  START_FILE=/tmp/.es_start_file

                  http () {
                    local path="${1}"
                    local args="${2}"
                    set -- -XGET -s

                    if [ "$args" != "" ]; then
                      set -- "$@" $args
                    fi

                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    fi

                    curl --output /dev/null -k "$@" "http://127.0.0.1:9200${path}"
                  }

                  if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy'
                    HTTP_CODE=$(http "/" "-w %{http_code}")
                    RC=$?
                    if [[ ${RC} -ne 0 ]]; then
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with RC ${RC}"
                      exit ${RC}
                    fi
                    # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                    if [[ ${HTTP_CODE} == "200" ]]; then
                      exit 0
                    elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                      exit 0
                    else
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                      exit 1
                    fi

                  else
                    echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=green&timeout=1s" "--fail" ; then
                      touch ${START_FILE}
                      exit 0
                    else
                      echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                      exit 1
                    fi
                  fi
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 1000m
              memory: 1Gi
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: cluster.initial_master_nodes
              value: elasticsearch-master-0,elasticsearch-master-1,
            - name: discovery.seed_hosts
              value: elasticsearch-master-headless
            - name: cluster.name
              value: elasticsearch
            - name: network.host
              value: 0.0.0.0
            - name: ES_JAVA_OPTS
              value: -Xmx1g -Xms1g
            - name: node.data
              value: "false"
            - name: node.ingest
              value: "false"
            - name: node.master
              value: "true"
            - name: XPACK_MONITORING_ENABLED
              value: "true"
          volumeMounts:
            - name: elasticsearch-master
              mountPath: /usr/share/elasticsearch/data
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-omxsq-test
  annotations:
    helm.sh/hook: test-success
spec:
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  containers:
    - name: release-name-uijsv-test
      image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl -XGET --fail 'elasticsearch-client:9200/_cluster/health?wait_for_status=green&timeout=1s'
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-ckitg-test
  annotations:
    helm.sh/hook: test-success
spec:
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  containers:
    - name: release-name-ihfxk-test
      image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl -XGET --fail 'elasticsearch-data:9200/_cluster/health?wait_for_status=green&timeout=1s'
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-gwugp-test
  annotations:
    helm.sh/hook: test-success
spec:
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  containers:
    - name: release-name-qflbd-test
      image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl -XGET --fail 'elasticsearch-master:9200/_cluster/health?wait_for_status=green&timeout=1s'
  restartPolicy: Never
