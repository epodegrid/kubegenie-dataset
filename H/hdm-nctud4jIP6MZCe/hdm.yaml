apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: hdm-deployement-elasticsearch-master-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: hdm-deployement-elasticsearch-master
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-mysql
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations: null
secrets:
  - name: release-name-mysql
---
apiVersion: v1
kind: Secret
metadata:
  name: release-name-mysql
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  mysql-root-password: cm9vdHBhc3N3b3Jk
  mysql-password: cGFzc3dvcmQ=
---
apiVersion: v1
data:
  conf-ldap.json: IiIK
kind: Secret
metadata:
  name: hdm-conf-ldap
---
apiVersion: v1
data:
  conf-db.json: IiIK
  create_tables.sql: IiIK
kind: Secret
metadata:
  name: hdm-conf-db
---
apiVersion: v1
data:
  conf-appli.json: IiIK
kind: Secret
metadata:
  name: hdm-conf-appli
---
apiVersion: v1
data:
  msmtprc: IiIK
kind: Secret
metadata:
  name: hdm-conf-mail
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mysql
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
data:
  my.cnf: |2-
    [mysqld]
    default_authentication_plugin=mysql_native_password
    skip-name-resolve
    explicit_defaults_for_timestamp
    basedir=/opt/bitnami/mysql
    plugin_dir=/opt/bitnami/mysql/lib/plugin
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    datadir=/bitnami/mysql/data
    tmpdir=/opt/bitnami/mysql/tmp
    max_allowed_packet=16M
    bind-address=0.0.0.0
    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
    log-error=/opt/bitnami/mysql/logs/mysqld.log
    character-set-server=UTF8
    collation-server=utf8_general_ci
    slow_query_log=0
    slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
    long_query_time=10.0

    [client]
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    default-character-set=UTF8
    plugin_dir=/opt/bitnami/mysql/lib/plugin

    [manager]
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
---
apiVersion: v1
data:
  version.json: |-
    {
    	"version": " 2.3.0 "
    }
kind: ConfigMap
metadata:
  name: release-name-version
---
kind: Service
apiVersion: v1
metadata:
  name: hdm-deployement-elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: hdm-deployement-elasticsearch-master
  annotations: {}
spec:
  type: ClusterIP
  selector:
    release: release-name
    chart: elasticsearch
    app: hdm-deployement-elasticsearch-master
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: hdm-deployement-elasticsearch-master-headless
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: hdm-deployement-elasticsearch-master
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: hdm-deployement-elasticsearch-master
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-kibana
  labels:
    app: kibana
    release: release-name
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5601
      protocol: TCP
      name: http
      targetPort: 5601
  selector:
    app: kibana
    release: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-mysql-headless
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations: null
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: mysql
      port: 3306
      targetPort: mysql
  selector:
    app.kubernetes.io/name: mysql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-mysql
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations: null
spec:
  type: ClusterIP
  ports:
    - name: mysql
      port: 3306
      protocol: TCP
      targetPort: mysql
      nodePort: null
  selector:
    app.kubernetes.io/name: mysql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-hdm
spec:
  type: ClusterIP
  ports:
    - name: 80tcp
      port: 80
      protocol: TCP
      targetPort: 80
  selector:
    app: release-name-hdm
    release: release-name
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-kibana
  labels:
    app: kibana
    release: release-name
    heritage: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: kibana
      release: release-name
  template:
    metadata:
      labels:
        app: kibana
        release: release-name
      annotations: null
    spec:
      automountServiceAccountToken: true
      securityContext:
        fsGroup: 1000
      volumes: null
      containers:
        - name: kibana
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 11411
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/kibana/kibana:7.16.1
          imagePullPolicy: IfNotPresent
          env:
            - name: ELASTICSEARCH_HOSTS
              value: http://hdm-deployement-elasticsearch-master:9200
            - name: SERVER_HOST
              value: 0.0.0.0
            - name: NODE_OPTIONS
              value: --max-old-space-size=1800
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e

                  # Disable nss cache to avoid filling dentry cache when calling curl
                  # This is required with Kibana Docker using nss < 3.52
                  export NSS_SDB_USE_CACHE=no

                  http () {
                      local path="${1}"
                      set -- -XGET -s --fail -L

                      if [ -n "${ELASTICSEARCH_USERNAME}" ] && [ -n "${ELASTICSEARCH_PASSWORD}" ]; then
                        set -- "$@" -u "${ELASTICSEARCH_USERNAME}:${ELASTICSEARCH_PASSWORD}"
                      fi

                      STATUS=$(curl --output /dev/null --write-out "%{http_code}" -k "$@" "http://localhost:5601${path}")
                      if [[ "${STATUS}" -eq 200 ]]; then
                        exit 0
                      fi

                      echo "Error: Got HTTP code ${STATUS} but expected a 200"
                      exit 1
                  }

                  http "/app/kibana"
          ports:
            - containerPort: 5601
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 1000m
              memory: 2Gi
          volumeMounts: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-hdm
  labels:
    app: release-name-hdm
    chart: hdm-2.4.5
    heritage: Helm
    release: release-name
    app.kubernetes.io/name: hdm
    helm.sh/chart: hdm-2.4.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 2.3.0
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: release-name-hdm
      release: release-name
  template:
    metadata:
      labels:
        app: release-name-hdm
        release: release-name
      annotations:
        rollme: FrvTa
    spec:
      containers:
        - name: hdm
          image: ghcr.io/curie-data-factory/hdm:2.3.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 80
              name: 80tcp
              protocol: TCP
          env:
            - name: APACHE_LOG_DIR
              value: /var/www/html/
            - name: APACHE_RUN_DIR
              value: /etc/apache2
            - name: APACHE_RUN_GROUP
              value: www-data
            - name: APACHE_RUN_USER
              value: www-data
          volumeMounts:
            - mountPath: /var/www/html/conf/appli/
              name: hdm-conf-appli
            - mountPath: /var/www/html/conf/db/
              name: hdm-conf-db
            - mountPath: /var/www/html/conf/ldap/
              name: hdm-conf-ldap
            - mountPath: /var/www/html/conf/mail/
              name: hdm-conf-mail
            - mountPath: /var/www/html/version/
              name: hdm-version
      volumes:
        - name: hdm-conf-appli
          secret:
            defaultMode: 511
            items:
              - key: conf-appli.json
                path: ./conf-appli.json
            secretName: hdm-conf-appli
        - name: hdm-conf-db
          secret:
            defaultMode: 511
            items:
              - key: conf-db.json
                path: ./conf-db.json
              - key: create_tables.sql
                path: ./create_tables.sql
            optional: false
            secretName: hdm-conf-db
        - name: hdm-conf-ldap
          secret:
            defaultMode: 511
            items:
              - key: conf-ldap.json
                path: ./conf-ldap.json
            secretName: hdm-conf-ldap
        - name: hdm-conf-mail
          secret:
            defaultMode: 511
            items:
              - key: msmtprc
                path: ./msmtprc
            secretName: hdm-conf-mail
        - name: hdm-version
          configMap:
            defaultMode: 511
            items:
              - key: version.json
                path: ./version.json
            name: release-name-version
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hdm-deployement-elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: hdm-deployement-elasticsearch-master
  annotations:
    esMajorVersion: "7"
spec:
  serviceName: hdm-deployement-elasticsearch-master-headless
  selector:
    matchLabels:
      app: hdm-deployement-elasticsearch-master
  replicas: 3
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: hdm-deployement-elasticsearch-master
      labels:
        release: release-name
        chart: elasticsearch
        app: hdm-deployement-elasticsearch-master
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      automountServiceAccountToken: true
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - hdm-deployement-elasticsearch-master
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      volumes: null
      enableServiceLinks: true
      initContainers:
        - name: configure-sysctl
          securityContext:
            runAsUser: 11662
            privileged: true
            capabilities:
              drop:
                "": NET_RAW
          image: docker.elastic.co/elasticsearch/elasticsearch:7.16.1
          imagePullPolicy: IfNotPresent
          command:
            - sysctl
            - -w
            - vm.max_map_count=262144
          resources:
            seccompProfile:
              type: RuntimeDefault
      containers:
        - name: elasticsearch
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 10917
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/elasticsearch/elasticsearch:7.16.1
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command:
                - bash
                - -c
                - |
                  set -e
                  # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=green&timeout=1s" )
                  # Once it has started only check that the node itself is responding
                  START_FILE=/tmp/.es_start_file

                  # Disable nss cache to avoid filling dentry cache when calling curl
                  # This is required with Elasticsearch Docker using nss < 3.52
                  export NSS_SDB_USE_CACHE=no

                  http () {
                    local path="${1}"
                    local args="${2}"
                    set -- -XGET -s

                    if [ "$args" != "" ]; then
                      set -- "$@" $args
                    fi

                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    fi

                    curl --output /dev/null -k "$@" "http://127.0.0.1:9200${path}"
                  }

                  if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy'
                    HTTP_CODE=$(http "/" "-w %{http_code}")
                    RC=$?
                    if [[ ${RC} -ne 0 ]]; then
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with RC ${RC}"
                      exit ${RC}
                    fi
                    # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                    if [[ ${HTTP_CODE} == "200" ]]; then
                      exit 0
                    elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                      exit 0
                    else
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                      exit 1
                    fi

                  else
                    echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=green&timeout=1s" "--fail" ; then
                      touch ${START_FILE}
                      exit 0
                    else
                      echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                      exit 1
                    fi
                  fi
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 1000m
              memory: 2Gi
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: cluster.initial_master_nodes
              value: hdm-deployement-elasticsearch-master-0,hdm-deployement-elasticsearch-master-1,hdm-deployement-elasticsearch-master-2,
            - name: discovery.seed_hosts
              value: hdm-deployement-elasticsearch-master-headless
            - name: cluster.name
              value: hdm-deployement-elasticsearch
            - name: network.host
              value: 0.0.0.0
            - name: cluster.deprecation_indexing.enabled
              value: "false"
            - name: node.data
              value: "true"
            - name: node.ingest
              value: "true"
            - name: node.master
              value: "true"
            - name: node.ml
              value: "true"
            - name: node.remote_cluster_client
              value: "true"
          volumeMounts: null
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-mysql
  namespace: nctud4jIP6MZCe
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-8.9.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mysql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  serviceName: release-name-mysql
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/configuration: f904bd3f9b345d6e79db9bd09efa6885955ad6b6f5276d1e1ffc5c85dd76b1d8
      labels:
        app.kubernetes.io/name: mysql
        helm.sh/chart: mysql-8.9.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: release-name-mysql
      affinity:
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mysql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                namespaces:
                  - default
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity: null
      securityContext:
        fsGroup: 1001
      containers:
        - name: mysql
          image: docker.io/bitnami/mysql:8.0.28-debian-10-r73
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 10454
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-mysql
                  key: mysql-root-password
            - name: MYSQL_USER
              value: hdm
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-mysql
                  key: mysql-password
            - name: MYSQL_DATABASE
              value: hdm
          ports:
            - name: mysql
              containerPort: 3306
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          startupProbe:
            failureThreshold: 10
            initialDelaySeconds: 15
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          resources:
            limits: {}
            requests: {}
            seccompProfile:
              type: RuntimeDefault
          volumeMounts:
            - name: data
              mountPath: /bitnami/mysql
            - name: config
              mountPath: /opt/bitnami/mysql/conf/my.cnf
              subPath: my.cnf
      volumes:
        - name: config
          configMap:
            name: release-name-mysql
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: mysql
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: primary
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 20Gi
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hdm-deployement-elasticsearch-master
  labels:
    app: elasticsearch
    release: release-name
    heritage: Helm
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - hdm-elastic.company.com
      secretName: hdm-elastic
  rules:
    - host: hdm-elastic.company.com
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: hdm-deployement-elasticsearch-master
                port:
                  number: 9200
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-kibana
  labels:
    app: kibana
    release: release-name
    heritage: Helm
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - hdm-kibana.company.com
      secretName: hdm-kibana
  rules:
    - host: hdm-kibana.company.com
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: release-name-kibana
                port:
                  number: 5601
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hdm
  labels:
    app: hdm
    chart: hdm-2.4.5
    heritage: Helm
    release: release-name
spec:
  tls:
    - hosts:
        - hdm.company.com
      secretName: hdm
  rules:
    - host: hdm.company.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: release-name-hdm
                port:
                  name: 80tcp
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-xghdv-test
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded
spec:
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  containers:
    - name: release-name-xyeln-test
      image: docker.elastic.co/elasticsearch/elasticsearch:7.16.1
      imagePullPolicy: IfNotPresent
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl -XGET --fail 'hdm-deployement-elasticsearch-master:9200/_cluster/health?wait_for_status=green&timeout=1s'
  restartPolicy: Never
