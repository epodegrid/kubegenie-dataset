apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hazelcast-configuration
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  hazelcast.yaml: |-
    hazelcast:
      jet:
        enabled: ${hz.jet.enabled}
      network:
        join:
          kubernetes:
            enabled: true
            namespace: ${namespace}
            service-name: ${serviceName}
        rest-api:
          enabled: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hazelcast-mancenter-configuration
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  hazelcast-client.yaml: |-
    hazelcast-client:
      network:
        kubernetes:
          enabled: true
          namespace: ${namespace}
          service-name: ${serviceName}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-hazelcast-default
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - endpoints
      - pods
      - nodes
      - services
    verbs:
      - get
      - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-hazelcast-default
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-hazelcast-default
subjects:
  - kind: ServiceAccount
    name: release-name-hazelcast
    namespace: default
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-hazelcast-mancenter
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: LoadBalancer
  selector:
    app.kubernetes.io/name: hazelcast-mancenter
    app.kubernetes.io/instance: release-name
    role: mancenter
  ports:
    - protocol: TCP
      port: 8080
      targetPort: mancenter
      name: http
    - protocol: TCP
      port: 443
      targetPort: mancenter
      name: https
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: hazelcast
    app.kubernetes.io/instance: release-name
    role: hazelcast
  ports:
    - protocol: TCP
      port: 5701
      targetPort: hazelcast
      name: hzport
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-hazelcast-mancenter
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: release-name-hazelcast-mancenter
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hazelcast-mancenter
      app.kubernetes.io/instance: release-name
      role: mancenter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hazelcast-mancenter
        helm.sh/chart: hazelcast-5.4.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        role: mancenter
    spec:
      hostNetwork: false
      hostPID: false
      hostIPC: false
      securityContext:
        fsGroup: 65534
      containers:
        - name: release-name-hazelcast-mancenter
          image: hazelcast/management-center:5.1.2
          imagePullPolicy: IfNotPresent
          resources: null
          ports:
            - name: mancenter
              containerPort: 8080
          livenessProbe:
            httpGet:
              path: /health
              port: 8081
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            tcpSocket:
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /config
            - name: mancenter-storage
              mountPath: /data
          env:
            - name: MC_INIT_CMD
              value: './bin/mc-conf.sh cluster add --lenient=true -H /data -cc /config/hazelcast-client.yaml; '
            - name: JAVA_OPTS
              value: ' -Dhazelcast.mc.healthCheck.enable=true -DserviceName=release-name-hazelcast -Dnamespace=default -Dhazelcast.mc.tls.enabled=false '
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
            runAsGroup: 65534
            privileged: false
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
      serviceAccountName: release-name-hazelcast
      automountServiceAccountToken: true
      volumes:
        - name: config
          configMap:
            name: release-name-hazelcast-mancenter-configuration
        - name: mancenter-storage
  volumeClaimTemplates:
    - metadata:
        name: mancenter-storage
        labels:
          app.kubernetes.io/name: hazelcast-mancenter
          helm.sh/chart: hazelcast-5.4.1
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/managed-by: Helm
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 8Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations: null
spec:
  serviceName: release-name-hazelcast
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: hazelcast
      app.kubernetes.io/instance: release-name
      role: hazelcast
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hazelcast
        helm.sh/chart: hazelcast-5.4.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        role: hazelcast
      annotations:
        checksum/hazelcast-config: c4b6a3fd48054c4013ca0c642202dfc072f46a56dd9e0062a942d6a8f565cb18
    spec:
      terminationGracePeriodSeconds: 600
      hostNetwork: false
      hostPID: false
      hostIPC: false
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
      containers:
        - name: release-name-hazelcast
          image: hazelcast/hazelcast:5.1.1
          imagePullPolicy: IfNotPresent
          resources: null
          ports:
            - name: hazelcast
              containerPort: 5701
              hostPort: null
          livenessProbe:
            httpGet:
              path: /hazelcast/health/node-state
              port: 5701
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /hazelcast/health/node-state
              port: 5701
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            successThreshold: 1
            failureThreshold: 10
          volumeMounts:
            - name: hazelcast-storage
              mountPath: /data/hazelcast
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: JAVA_OPTS
              value: '-Dhazelcast.config=/data/hazelcast/hazelcast.yaml -DserviceName=release-name-hazelcast -Dnamespace=default -Dhz.jet.enabled=true -Dhazelcast.shutdownhook.policy=GRACEFUL -Dhazelcast.shutdownhook.enabled=true -Dhazelcast.graceful.shutdown.max.wait=600   '
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
            runAsGroup: 65534
            privileged: false
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
      serviceAccountName: release-name-hazelcast
      automountServiceAccountToken: true
      volumes:
        - name: hazelcast-storage
          configMap:
            name: release-name-hazelcast-configuration
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-hazelcast-test-1mgjx
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded, hook-failed
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: test
    role: test
spec:
  containers:
    - name: release-name-hazelcast-test
      image: alpine:latest
      command:
        - sh
        - -c
        - |
          set -ex
          # Install required test tools
          apk add -q curl
          # Get the number of Hazelcast members in the cluster
          CLUSTER_SIZE=$(curl release-name-hazelcast:5701/hazelcast/health/cluster-size)
          # Test the correct number of Hazelcast members
          test ${CLUSTER_SIZE} -eq 3
      resources: null
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-hazelcast-mancenter-test-amv1p
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded, hook-failed
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: test
    role: test
spec:
  containers:
    - name: release-name-hazelcast-mancenter-test
      image: alpine:latest
      command:
        - sh
        - -c
        - |
          set -ex
          # Install required test tools
          apk add -q jq curl
          # Get the HTTP Response Code of the Health Check
          HEALTH_CHECK_HTTP_RESPONSE_CODE=$(curl --write-out %{http_code} --silent --output /dev/null release-name-hazelcast-mancenter:8080/health)
          # Test the MC HTTP RESPONSE CODE
          test ${HEALTH_CHECK_HTTP_RESPONSE_CODE} -eq 200
          # Get the connected cluster count via /rest/clusters/dev/members endpoint
          CONNECTED_CLUSTER_SIZE=$(curl --silent release-name-hazelcast-mancenter:8080/rest/clusters/dev/members | jq '. | length')
          # Test the correct number of Hazelcast members
          test ${CONNECTED_CLUSTER_SIZE} -eq 3
      resources: null
  restartPolicy: Never
